{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Default Setting",
   "id": "77548af6180db51c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-20T02:59:07.384820Z",
     "start_time": "2024-12-20T02:59:03.817366Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 가져오기\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import wandb\n",
    "\n",
    "# 데이터 로더 관련 커스텀 모듈 가져오기\n",
    "from _01_code._03_real_world_data_to_tensors.p_cryptocurrency_dataset_dataloader import (\n",
    "    get_cryptocurrency_data,\n",
    "    CryptoCurrencyDataset,\n",
    ")\n",
    "\n",
    "# 주피터 노트북에서는 os.getcwd()로 현재 작업 디렉토리 설정\n",
    "CURRENT_FILE_PATH = os.getcwd()\n",
    "\n",
    "# 체크포인트 파일 저장 경로 설정\n",
    "CHECKPOINT_FILE_PATH = os.path.join(CURRENT_FILE_PATH, \"checkpoints\")\n",
    "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
    "    os.makedirs(CHECKPOINT_FILE_PATH)\n",
    "\n",
    "# Wandb 설정 초기화\n",
    "wandb.init(\n",
    "    project=\"lstm_classification_btc_krw_next_open\",  # 프로젝트 이름\n",
    "    name=f\"BTC_KRW_Classification_Next_Open_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",  # 실험 이름\n",
    "    config={\n",
    "        \"epochs\": 30,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 1e-3,\n",
    "    }\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:av8w5sl0) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.009 MB of 0.009 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07eb0cb1727e47d29b632b77de0c1441"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>Test Accuracy</td><td>▁</td></tr><tr><td>Train Loss</td><td>█▆▆▅▆▅▅▅▅▆▆▄▄▅▄▅▄▅▄▄▄▅▄█▃▄▅▄▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>30</td></tr><tr><td>Test Accuracy</td><td>70</td></tr><tr><td>Train Loss</td><td>0.69045</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">BTC_KRW_Classification_Next_Open_20241220_115643</strong> at: <a href='https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open/runs/av8w5sl0' target=\"_blank\">https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open/runs/av8w5sl0</a><br/> View project at: <a href='https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open' target=\"_blank\">https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241220_115643-av8w5sl0\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:av8w5sl0). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\yscho\\git\\link_dl\\_02_homeworks\\homework_4\\wandb\\run-20241220_115903-78acrm9v</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open/runs/78acrm9v' target=\"_blank\">BTC_KRW_Classification_Next_Open_20241220_115903</a></strong> to <a href='https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open' target=\"_blank\">https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open/runs/78acrm9v' target=\"_blank\">https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open/runs/78acrm9v</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/yuuun03-korea-university-of-technology-and-education/lstm_classification_btc_krw_next_open/runs/78acrm9v?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x204962c0520>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model",
   "id": "aa84cfe6314043e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T02:59:07.414718Z",
     "start_time": "2024-12-20T02:59:07.393410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LSTM 모델 정의\n",
    "class MyModel(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM 기반 분류 모델 정의\n",
    "    \"\"\"\n",
    "    def __init__(self, n_input, n_output):\n",
    "        \"\"\"\n",
    "        모델 초기화 함수.\n",
    "\n",
    "        Args:\n",
    "            n_input (int): 입력 데이터의 feature 개수\n",
    "            n_output (int): 출력 데이터의 클래스 수\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_input,  # 입력 feature 개수\n",
    "            hidden_size=256,  # LSTM 은닉 상태 크기\n",
    "            num_layers=3,  # LSTM 레이어 수\n",
    "            batch_first=True  # 데이터 형식: [batch, sequence, feature]\n",
    "        )\n",
    "        self.fcn = nn.Linear(in_features=256, out_features=n_output)  # 최종 Fully Connected Layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파 함수.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): 입력 데이터 (shape: [batch_size, sequence_length, input_features])\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 모델 출력 (shape: [batch_size, n_output])\n",
    "        \"\"\"\n",
    "        x, _ = self.lstm(x)  # LSTM 레이어 통과\n",
    "        x = x[:, -1, :]  # 시퀀스의 마지막 출력값 사용\n",
    "        x = self.fcn(x)  # Fully Connected Layer 통과\n",
    "        return x"
   ],
   "id": "df4de8a7846683ab",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loader",
   "id": "446767c3a4288098"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T02:59:07.452039Z",
     "start_time": "2024-12-20T02:59:07.439972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 데이터 로드 함수\n",
    "def get_btc_krw_data(sequence_size=10, validation_size=100, test_size=10, is_regression=False):\n",
    "    \"\"\"\n",
    "    암호화폐 데이터를 로드하여 학습/검증/테스트용 DataLoader로 변환.\n",
    "\n",
    "    Args:\n",
    "        sequence_size (int): 입력 데이터의 시퀀스 길이\n",
    "        validation_size (int): 검증 데이터 크기\n",
    "        test_size (int): 테스트 데이터 크기\n",
    "        is_regression (bool): 회귀 여부 (False: 분류 문제)\n",
    "\n",
    "    Returns:\n",
    "        tuple: 학습, 검증, 테스트 데이터 로더\n",
    "    \"\"\"\n",
    "    # 데이터를 로드하고 전처리\n",
    "    X_train, X_validation, X_test, y_train, y_validation, y_test, _, _, _ = get_cryptocurrency_data(\n",
    "        sequence_size=sequence_size,\n",
    "        validation_size=validation_size,\n",
    "        test_size=test_size,\n",
    "        target_column=\"Close\",  # 타겟 데이터 열 이름\n",
    "        y_normalizer=1.0e7,  # 데이터 정규화 상수\n",
    "        is_regression=is_regression,  # 회귀/분류 선택\n",
    "        include_next_open=True  # `next_open` 속성을 포함하도록 설정\n",
    "    )\n",
    "\n",
    "    # 분류 문제일 경우 레이블을 torch.long 타입으로 변환\n",
    "    if not is_regression:\n",
    "        y_train = y_train.to(torch.long)\n",
    "        y_validation = y_validation.to(torch.long)\n",
    "        y_test = y_test.to(torch.long)\n",
    "\n",
    "    # 학습 데이터셋 생성\n",
    "    train_dataset = CryptoCurrencyDataset(X=X_train, y=y_train)\n",
    "    \n",
    "    # 검증 데이터셋 생성\n",
    "    validation_dataset = CryptoCurrencyDataset(X=X_validation, y=y_validation)\n",
    "    \n",
    "    # 테스트 데이터셋 생성\n",
    "    test_dataset = CryptoCurrencyDataset(X=X_test, y=y_test)\n",
    "\n",
    "    # DataLoader 생성 (배치 크기 설정 및 셔플 여부 지정)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "    validation_loader = DataLoader(dataset=validation_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "    return train_loader, validation_loader, test_loader\n"
   ],
   "id": "b2fc48f9977d33e7",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train",
   "id": "7b09ce18bc1a0714"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T02:59:07.483078Z",
     "start_time": "2024-12-20T02:59:07.471239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, train_loader, validation_loader, device, epochs=30, lr=1e-3):\n",
    "    \"\"\"\n",
    "    모델 학습 함수.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 학습할 모델(LSTM 기반 분류 모델)\n",
    "        train_loader (DataLoader): 학습 데이터 로더\n",
    "        validation_loader (DataLoader): 검증 데이터 로더\n",
    "        device (torch.device): 학습 장치 (GPU 또는 CPU)\n",
    "        epochs (int): 학습 반복 횟수\n",
    "        lr (float): 학습률\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # Adam 옵티마이저\n",
    "    criterion = nn.CrossEntropyLoss()  # 분류 문제용 손실 함수\n",
    "\n",
    "    model.to(device)  # 모델을 장치로 이동\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # 학습 모드 활성화\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).long()\n",
    "\n",
    "            optimizer.zero_grad()  # 그래디언트 초기화\n",
    "            output = model(X_batch)  # 모델 출력 계산\n",
    "            loss = criterion(output, y_batch)  # 손실 계산\n",
    "            loss.backward()  # 역전파\n",
    "            optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {train_loss:.4f}\")\n",
    "        wandb.log({\"Train Loss\": train_loss, \"Epoch\": epoch + 1})\n"
   ],
   "id": "c118c9778fb57ce2",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test",
   "id": "7dad963314c56800"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T02:59:07.544783Z",
     "start_time": "2024-12-20T02:59:07.530604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    모델 테스트 함수\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 학습된 모델\n",
    "        test_loader (DataLoader): 테스트 데이터 로더\n",
    "        device (torch.device): 실행 장치\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "\n",
    "    print(\"[TEST DATA]\")\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            num_correct += (predictions == y_batch).sum().item()\n",
    "            num_samples += y_batch.size(0)\n",
    "\n",
    "    accuracy = 100.0 * num_correct / num_samples\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    wandb.log({\"Test Accuracy\": accuracy})"
   ],
   "id": "2c3634f76ab48381",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Main",
   "id": "b755499f6ecf60ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T03:01:11.289601Z",
     "start_time": "2024-12-20T02:59:07.580605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    데이터 로드, 모델 학습 및 테스트 실행\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # `next_open` 속성을 포함하여 데이터 로드\n",
    "    train_loader, validation_loader, test_loader = get_btc_krw_data()\n",
    "\n",
    "    # 모델 생성 (입력 feature 개수를 6으로 설정)\n",
    "    model = MyModel(n_input=6, n_output=2)\n",
    "\n",
    "    # 모델 학습\n",
    "    train(model, train_loader, validation_loader, device, epochs=30, lr=1e-3)\n",
    "\n",
    "    # 모델 테스트\n",
    "    test(model, test_loader, device)\n",
    "\n",
    "# 코드 실행\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "614dffb316c7c16b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yscho\\git\\link_dl\\_01_code\\_03_real_world_data_to_tensors\\p_cryptocurrency_dataset_dataloader.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)  # 입력 데이터는 항상 float32로 저장\n",
      "C:\\Users\\yscho\\git\\link_dl\\_01_code\\_03_real_world_data_to_tensors\\p_cryptocurrency_dataset_dataloader.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(y, dtype=torch.float32)  # 회귀 문제일 경우 float32로 저장\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.6918\n",
      "[Epoch 2] Train Loss: 0.6916\n",
      "[Epoch 3] Train Loss: 0.6925\n",
      "[Epoch 4] Train Loss: 0.6917\n",
      "[Epoch 5] Train Loss: 0.6914\n",
      "[Epoch 6] Train Loss: 0.6918\n",
      "[Epoch 7] Train Loss: 0.6910\n",
      "[Epoch 8] Train Loss: 0.6912\n",
      "[Epoch 9] Train Loss: 0.6908\n",
      "[Epoch 10] Train Loss: 0.6911\n",
      "[Epoch 11] Train Loss: 0.6912\n",
      "[Epoch 12] Train Loss: 0.6908\n",
      "[Epoch 13] Train Loss: 0.6910\n",
      "[Epoch 14] Train Loss: 0.6914\n",
      "[Epoch 15] Train Loss: 0.6910\n",
      "[Epoch 16] Train Loss: 0.6909\n",
      "[Epoch 17] Train Loss: 0.6906\n",
      "[Epoch 18] Train Loss: 0.6912\n",
      "[Epoch 19] Train Loss: 0.6912\n",
      "[Epoch 20] Train Loss: 0.6909\n",
      "[Epoch 21] Train Loss: 0.6911\n",
      "[Epoch 22] Train Loss: 0.6907\n",
      "[Epoch 23] Train Loss: 0.6906\n",
      "[Epoch 24] Train Loss: 0.6916\n",
      "[Epoch 25] Train Loss: 0.6913\n",
      "[Epoch 26] Train Loss: 0.6906\n",
      "[Epoch 27] Train Loss: 0.6904\n",
      "[Epoch 28] Train Loss: 0.6903\n",
      "[Epoch 29] Train Loss: 0.6907\n",
      "[Epoch 30] Train Loss: 0.6905\n",
      "[TEST DATA]\n",
      "Accuracy: 70.00%\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Next_open 추가시 정확도가 70%->80%로 향상된 이유\n",
    "next_open 피처를 포함했을 때 분류 정확도가 70%에서 80%로 상승한 이유는 이 피처가 다음 날의 시장 움직임과 강한 상관관계를 가지기 때문이다. 이 추가 피처는 모델이 시계열 데이터에서 가격 변동 패턴을 더 명확히 학습하도록 돕는다. 특히 next_open은 과거 데이터의 트렌드와 연속성을 보완하여 모델의 예측 능력을 강화한다. 반대로 이 피처가 없을 경우 모델은 불완전한 데이터에 의존하여 패턴을 학습하기 때문에 예측 성능이 낮아질 수 있다. 따라서, 주요 상관 피처를 추가하는 것은 분류 문제에서 모델의 성능을 크게 향상시키는 데 기여한다."
   ],
   "id": "4533d9e677dbfc7d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 숙제 후기\n",
    "\n",
    "이 코드를 구현하며 가장 어려웠던 점은 next_open 피처를 시계열 데이터에 추가하고 이를 모델에 통합하는 과정이었다. 특히 데이터 전처리에서 연속된 행 간의 관계를 유지하면서 결측값 처리와 학습 데이터 분할에 신경 써야 했다. next_open 피처는 시계열 데이터에서 다음 날의 가격 움직임을 미리 반영할 수 있어 모델이 시계열 패턴을 더 효과적으로 학습하도록 돕는다. 이러한 피처는 시계열 데이터에서 과거와 미래 간의 상관성을 강조하며 예측 정확도와 안정성을 크게 향상시키는 데 중요한 역할을 한다. 이번 작업을 통해 피처 엔지니어링이 시계열 문제 해결의 핵심이라는 점을 실감하게 되었다."
   ],
   "id": "73b287dfd5113a91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
